\doxysection{Sigmoid\texorpdfstring{$<$}{<} T \texorpdfstring{$>$}{>} Class Template Reference}
\hypertarget{classSigmoid}{}\label{classSigmoid}\index{Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}}


Capa de activación \doxylink{classutec_1_1neural__network_1_1Sigmoid}{Sigmoid}. Convierte cada valor en el rango (0, 1) abierto usando la función logística. No tiene parámetros entrenables.  




{\ttfamily \#include $<$activation.\+h$>$}



Inheritance diagram for Sigmoid\texorpdfstring{$<$}{<} T \texorpdfstring{$>$}{>}\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=185pt]{classSigmoid__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for Sigmoid\texorpdfstring{$<$}{<} T \texorpdfstring{$>$}{>}\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=185pt]{classSigmoid__coll__graph}
\end{center}
\end{figure}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
auto \mbox{\hyperlink{classSigmoid_a70102144b4313b2c7e6564d429cfd2ff}{forward}} (const algebra\+::\+Tensor$<$ T, 2 $>$ \&z) -\/$>$ algebra\+::\+Tensor$<$ T, 2 $>$ override
\begin{DoxyCompactList}\small\item\em Propagación hacia adelante aplicando sigmoide. \end{DoxyCompactList}\item 
auto \mbox{\hyperlink{classSigmoid_adf8a7cea25b499a7dbfffd6bd95da147}{backward}} (const algebra\+::\+Tensor$<$ T, 2 $>$ \&g) -\/$>$ algebra\+::\+Tensor$<$ T, 2 $>$ override
\begin{DoxyCompactList}\small\item\em Propagación hacia atrás\+: gradiente de la función sigmoide. \end{DoxyCompactList}\item 
auto \mbox{\hyperlink{classSigmoid_ab5e62d3ebf0ddb9ef958bbe2c991ab37}{id}} () const -\/$>$ Layer\+Id override
\begin{DoxyCompactList}\small\item\em Identificador único de la capa \doxylink{classutec_1_1neural__network_1_1Sigmoid}{Sigmoid}. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions inherited from \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer}{utec\+::neural\+\_\+network\+::\+ILayer$<$ T $>$}}}
\begin{DoxyCompactItemize}
\item 
virtual \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a6965ff90722a8ff3929fa55a1fd722f2}{\texorpdfstring{$\sim$}{\string~}\+ILayer}} ()=default
\begin{DoxyCompactList}\small\item\em Destructor virtual. \end{DoxyCompactList}\item 
virtual auto \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a22275b736574bf1ef9febb9889ba7a25}{forward}} (const \mbox{\hyperlink{classutec_1_1algebra_1_1Tensor}{algebra\+::\+Tensor}}$<$ T, 2 $>$ \&\mbox{\hyperlink{catch__amalgamated_8cpp_a6abfb3eb1e8098e09b8a4d1fc295b265}{x}}) -\/$>$ \mbox{\hyperlink{classutec_1_1algebra_1_1Tensor}{algebra\+::\+Tensor}}$<$ T, 2 $>$=0
\begin{DoxyCompactList}\small\item\em Propagación hacia adelante de la capa. \end{DoxyCompactList}\item 
virtual auto \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a1edb042d919a28e28c1523c1c29df07f}{backward}} (const \mbox{\hyperlink{classutec_1_1algebra_1_1Tensor}{algebra\+::\+Tensor}}$<$ T, 2 $>$ \&gradients) -\/$>$ \mbox{\hyperlink{classutec_1_1algebra_1_1Tensor}{algebra\+::\+Tensor}}$<$ T, 2 $>$=0
\begin{DoxyCompactList}\small\item\em Propagación hacia atrás de la capa. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a07d2e3abb2656a40eef1dc4de099c86f}{update\+\_\+params}} (\mbox{\hyperlink{structutec_1_1neural__network_1_1IOptimizer}{IOptimizer}}$<$ T $>$ \&optimizer)
\begin{DoxyCompactList}\small\item\em Actualiza los parámetros internos de la capa (si tiene). \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a0ddf898a100cec73a4e0df30caa6952e}{save}} (std\+::ostream \&out) const
\begin{DoxyCompactList}\small\item\em Guarda los parámetros internos de la capa en un flujo binario. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\subsubsection*{template$<$typename T$>$\newline
class Sigmoid$<$ T $>$}
Capa de activación \doxylink{classutec_1_1neural__network_1_1Sigmoid}{Sigmoid}. Convierte cada valor en el rango (0, 1) abierto usando la función logística. No tiene parámetros entrenables. 


\begin{DoxyTemplParams}{Template Parameters}
{\em T} & Tipo de dato (usualmente float o double). \\
\hline
\end{DoxyTemplParams}


\label{doc-func-members}
\Hypertarget{classSigmoid_doc-func-members}
\doxysubsection{Member Function Documentation}
\Hypertarget{classSigmoid_adf8a7cea25b499a7dbfffd6bd95da147}\index{Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}!backward@{backward}}
\index{backward@{backward}!Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}}
\doxysubsubsection{\texorpdfstring{backward()}{backward()}}
{\footnotesize\ttfamily \label{classSigmoid_adf8a7cea25b499a7dbfffd6bd95da147} 
template$<$typename T$>$ \\
auto \mbox{\hyperlink{classutec_1_1neural__network_1_1Sigmoid}{utec\+::neural\+\_\+network\+::\+Sigmoid}}$<$ T $>$\+::backward (\begin{DoxyParamCaption}\item[{const algebra\+::\+Tensor$<$ T, 2 $>$ \&}]{g}{}\end{DoxyParamCaption}) -\/$>$ algebra\+::\+Tensor$<$T, 2$>$\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [override]}}



Propagación hacia atrás\+: gradiente de la función sigmoide. 


\begin{DoxyParams}{Parameters}
{\em g} & Gradiente de la siguiente capa. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Gradiente respecto a la entrada de esta capa. @complexity O(n\texorpdfstring{$\ast$}{*}m\texorpdfstring{$\ast$}{*}r), donde\+: n\texorpdfstring{$\ast$}{*}m es el tamaño del tensor de salida, r es el número de dimensiones del resultado (por broadcasting). En la práctica, si no hay broadcasting, se reduce a O(n\texorpdfstring{$\ast$}{*}m). 
\end{DoxyReturn}
\Hypertarget{classSigmoid_a70102144b4313b2c7e6564d429cfd2ff}\index{Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}!forward@{forward}}
\index{forward@{forward}!Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}}
\doxysubsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily \label{classSigmoid_a70102144b4313b2c7e6564d429cfd2ff} 
template$<$typename T$>$ \\
auto \mbox{\hyperlink{classutec_1_1neural__network_1_1Sigmoid}{utec\+::neural\+\_\+network\+::\+Sigmoid}}$<$ T $>$\+::forward (\begin{DoxyParamCaption}\item[{const algebra\+::\+Tensor$<$ T, 2 $>$ \&}]{z}{}\end{DoxyParamCaption}) -\/$>$ algebra\+::\+Tensor$<$T, 2$>$\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [override]}}



Propagación hacia adelante aplicando sigmoide. 


\begin{DoxyParams}{Parameters}
{\em z} & \doxylink{classTensor}{Tensor} de entrada. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
\doxylink{classTensor}{Tensor} con valores entre 0 y 1. @complexity O(n\texorpdfstring{$\ast$}{*}m), dado un tensor de entrada z de tamaño n\texorpdfstring{$\ast$}{*}m. 
\end{DoxyReturn}
\Hypertarget{classSigmoid_ab5e62d3ebf0ddb9ef958bbe2c991ab37}\index{Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}!id@{id}}
\index{id@{id}!Sigmoid$<$ T $>$@{Sigmoid$<$ T $>$}}
\doxysubsubsection{\texorpdfstring{id()}{id()}}
{\footnotesize\ttfamily \label{classSigmoid_ab5e62d3ebf0ddb9ef958bbe2c991ab37} 
template$<$typename T$>$ \\
auto \mbox{\hyperlink{classutec_1_1neural__network_1_1Sigmoid}{utec\+::neural\+\_\+network\+::\+Sigmoid}}$<$ T $>$\+::id (\begin{DoxyParamCaption}{}{}\end{DoxyParamCaption}) const -\/$>$ Layer\+Id\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [nodiscard]}, {\ttfamily [override]}, {\ttfamily [virtual]}}



Identificador único de la capa \doxylink{classutec_1_1neural__network_1_1Sigmoid}{Sigmoid}. 

\begin{DoxyReturn}{Returns}
Layer\+ID\+::\+Sigmoid (o bien 1) @complexity O(1). 
\end{DoxyReturn}


Implements \mbox{\hyperlink{structutec_1_1neural__network_1_1ILayer_a16b50cd81a4b1c368797af2cce2b7d06}{utec\+::neural\+\_\+network\+::\+ILayer$<$ T $>$}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
include/utec/nn/\mbox{\hyperlink{activation_8h}{activation.\+h}}\end{DoxyCompactItemize}
